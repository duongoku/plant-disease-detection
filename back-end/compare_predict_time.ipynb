{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x[\"val_acc\"] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n",
    "\n",
    "\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class CNN_NeuralNet(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "\n",
    "        self.conv3 = ConvBlock(128, 256, pool=True)\n",
    "        self.conv4 = ConvBlock(256, 512, pool=True)\n",
    "\n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(4), nn.Flatten(), nn.Linear(512, num_diseases)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda available\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"cuda not available\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def predict_image(image_path, model, class_names, device):\n",
    "    \"\"\"\n",
    "    Make prediction for a single image and measure inference time\n",
    "    \"\"\"\n",
    "    transform = transforms.ToTensor()\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((256, 256))\n",
    "    img_tensor = transform(img)\n",
    "\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        outputs = model(img_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        inference_time = (time.time() - start_time) * 1000\n",
    "\n",
    "    return class_names[predicted.item()], inference_time\n",
    "\n",
    "\n",
    "def compare_inference_times(model, data_dir, class_names, num_images=50):\n",
    "    \"\"\"\n",
    "    Compare inference times between CPU and GPU\n",
    "    \"\"\"\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    gpu_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    cpu_times = []\n",
    "    gpu_times = []\n",
    "\n",
    "    image_files = os.listdir(data_dir)[:num_images]\n",
    "\n",
    "    # CPU inference\n",
    "    model = model.to(cpu_device)\n",
    "    print(\"\\nRunning CPU inference...\")\n",
    "    for file_name in image_files:\n",
    "        image_path = os.path.join(data_dir, file_name)\n",
    "        _, inference_time = predict_image(image_path, model, class_names, cpu_device)\n",
    "        cpu_times.append(inference_time)\n",
    "\n",
    "    # GPU inference\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(gpu_device)\n",
    "        print(\"\\nRunning GPU inference...\")\n",
    "        for file_name in image_files:\n",
    "            image_path = os.path.join(data_dir, file_name)\n",
    "            _, inference_time = predict_image(\n",
    "                image_path, model, class_names, gpu_device\n",
    "            )\n",
    "            gpu_times.append(inference_time)\n",
    "\n",
    "    print(\"\\nPerformance Comparison:\")\n",
    "    print(f\"CPU - Average inference time: {sum(cpu_times)/len(cpu_times):.2f} ms\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU - Average inference time: {sum(gpu_times)/len(gpu_times):.2f} ms\")\n",
    "        print(f\"Speedup: {sum(cpu_times)/sum(gpu_times):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n",
      "\n",
      "Running CPU inference...\n",
      "\n",
      "Running GPU inference...\n",
      "\n",
      "Performance Comparison:\n",
      "CPU - Average inference time: 102.97 ms\n",
      "GPU - Average inference time: 10.74 ms\n",
      "Speedup: 9.58x\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = get_default_device()\n",
    "    checkpoint = torch.load(\"plant_disease_model.pth\", map_location=device)\n",
    "\n",
    "    num_classes = len(checkpoint[\"class_names\"])\n",
    "    model = CNN_NeuralNet(3, num_classes)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    data_dir = \"D:\\\\UET\\\\GRAD_SCHOOL\\\\AIE\\\\project\\\\plantvillage dataset\\\\grayscale\\\\Potato___Late_blight\"\n",
    "    compare_inference_times(model, data_dir, checkpoint[\"class_names\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
